# PhaseProfiler Backend

Backend logic for PhaseProfiler web application. Handles profiling, AI classification, recommendations, and serving data to the frontend.

## ğŸ“ Structure

```
backend/
â”œâ”€â”€ app.py                  # Flask server (routes, API endpoints)
â”œâ”€â”€ phaseprofiler.py        # Mono profiler script (collect metrics, detect phases, save CSV)
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ data/                   # Profiling run datasets
â”‚   â””â”€â”€ training_data.csv  # Example collected metrics
â”œâ”€â”€ models/                 # Trained ML models
â”‚   â”œâ”€â”€ bottleneck_classifier.pkl   # Random Forest classifier
â”‚   â””â”€â”€ regression_model.pkl        # Speedup predictor
â”œâ”€â”€ notebooks/              # Training notebooks
â”‚   â””â”€â”€ train_model.ipynb  # Train classifier/regression models using CSV data
â””â”€â”€ tests/                  # Unit tests
    â””â”€â”€ test_profiler.py   # Test metric collection + phase detection
```

## ğŸš€ Setup

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Run the Flask server:**
   ```bash
   python app.py
   ```

   The server will start on `http://localhost:5000`

## ğŸ“Š Usage

### Running the Profiler

**Option 1: Via Flask API**
- Start the Flask server: `python app.py`
- Use the web interface at `http://localhost:5000`
- Or call the API endpoints directly (see API Documentation below)

**Option 2: Command-line**
```bash
# Profile system-wide metrics for 60 seconds
python phaseprofiler.py --duration 60 --output data/training_data.csv

# Profile a specific program
python phaseprofiler.py /path/to/program.py --duration 120
```

### Training Models

1. Collect training data using the profiler
2. Open `notebooks/train_model.ipynb` in Jupyter
3. Follow the notebook to train classifier and regression models
4. Save trained models to `models/` directory

## ğŸ”Œ API Endpoints

### `GET /`
Homepage - start profiling interface

### `GET /dashboard`
Interactive dashboard showing metrics, phases, and bottlenecks

### `GET /results`
Results page showing recommendations and predicted impact

### `POST /api/profile`
Start profiling a program
- Request body: `{"program_path": "...", "duration": 60}`
- Returns: `{"status": "success", "output_file": "training_data.csv"}`

### `GET /api/metrics`
Get collected metrics data
- Returns: `{"status": "success", "metrics": [...], "count": N}`

### `POST /api/classify`
Classify bottlenecks using trained ML model
- Request body: `{"features": [[...], [...]]}`
- Returns: `{"status": "success", "predictions": [...], "probabilities": [...]}`

### `POST /api/predict-speedup`
Predict optimization speedup using regression model
- Request body: `{"features": [[...], [...]]}`
- Returns: `{"status": "success", "speedup": [...], "predicted_improvement": "..."}`

### `GET /api/health`
Health check endpoint
- Returns: `{"status": "healthy", "timestamp": "...", "models_available": {...}}`

## ğŸ§ª Testing

Run unit tests:
```bash
python -m pytest tests/
```

Or run individual test file:
```bash
python tests/test_profiler.py
```

## ğŸ“ Responsibilities

- **Collect metrics** (CPU, I/O, memory) â†’ `phaseprofiler.py`
- **Detect phases** â†’ `phaseprofiler.py`
- **Train models** â†’ `notebooks/train_model.ipynb`
- **Store datasets** â†’ `data/`
- **Serve results via Flask API** â†’ `app.py`
- **Load models** â†’ `models/`

## ğŸ”§ Configuration

- Default profiling duration: 60 seconds
- Default sampling interval: 1 second
- Max upload file size: 16MB
- Models location: `models/`
- Data location: `data/`

